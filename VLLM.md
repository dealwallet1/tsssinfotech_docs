[How-to Install vLLM and Serve AI Models Locally](https://www.youtube.com/watch?v=9gX5bgtvuUU)

[How to Run Multiple vLLM Models on Free GPUs Like a Pro](https://medium.com/@hoaithuong.data/how-to-run-multiple-vllm-models-on-free-gpus-like-a-pro-bf59e9b8bacc)